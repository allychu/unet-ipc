{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7W8QcRMxG_x",
        "outputId": "18a31045-c2ce-4950-e156-f93505f79e4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "  → Training batch 1/750\n",
            "  → Training batch 2/750\n",
            "  → Training batch 3/750\n",
            "  → Training batch 4/750\n",
            "  → Training batch 5/750\n",
            "  → Training batch 6/750\n",
            "  → Training batch 7/750\n",
            "  → Training batch 8/750\n",
            "  → Training batch 9/750\n",
            "  → Training batch 10/750\n",
            "  → Training batch 11/750\n",
            "  → Training batch 12/750\n",
            "  → Training batch 13/750\n",
            "  → Training batch 14/750\n",
            "  → Training batch 15/750\n",
            "  → Training batch 16/750\n",
            "  → Training batch 17/750\n",
            "  → Training batch 18/750\n",
            "  → Training batch 19/750\n"
          ]
        }
      ],
      "source": [
        "# === Mount Google Drive ===\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ==============================\n",
        "# DAWN MODULE\n",
        "# ==============================\n",
        "class DAWN(nn.Module):\n",
        "    \"\"\"\n",
        "    DAWN module: Learns IPC-like filters as a trainable preprocessing layer.\n",
        "    This module takes raw images and produces augmented feature maps that\n",
        "    highlight edges/structures at multiple scales.\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels: int):\n",
        "        super(DAWN, self).__init__()\n",
        "        self.in_channels = in_channels\n",
        "        # fine-scale edge detection\n",
        "        self.conv_fine = nn.Conv2d(in_channels, 1, kernel_size=3, padding=1)\n",
        "        # coarse-scale structure detection\n",
        "        self.conv_coarse = nn.Conv2d(in_channels, 1, kernel_size=3, padding=4, dilation=4)\n",
        "        # weight initialization\n",
        "        nn.init.kaiming_normal_(self.conv_fine.weight, nonlinearity='relu')\n",
        "        nn.init.constant_(self.conv_fine.bias, 0.0)\n",
        "        nn.init.kaiming_normal_(self.conv_coarse.weight, nonlinearity='relu')\n",
        "        nn.init.constant_(self.conv_coarse.bias, 0.0)\n",
        "        self.out_channels = in_channels + 2\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        fine = F.relu(self.conv_fine(x))\n",
        "        coarse = F.relu(self.conv_coarse(x))\n",
        "        out = torch.cat([x, fine, coarse], dim=1)\n",
        "        return out\n",
        "\n",
        "\n",
        "# ==============================\n",
        "# U-NET\n",
        "# ==============================\n",
        "class DoubleConv(nn.Module):\n",
        "    def __init__(self, in_channels: int, out_channels: int):\n",
        "        super(DoubleConv, self).__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        return self.net(x)\n",
        "\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, in_channels: int, out_classes: int = 1):\n",
        "        super(UNet, self).__init__()\n",
        "        features = [64, 128, 256, 512]\n",
        "        self.enc_blocks = nn.ModuleList()\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        prev_channels = in_channels\n",
        "        for feat in features:\n",
        "            self.enc_blocks.append(DoubleConv(prev_channels, feat))\n",
        "            prev_channels = feat\n",
        "        self.bottleneck = DoubleConv(prev_channels, prev_channels * 2)\n",
        "        bottleneck_channels = prev_channels * 2  # store for clarity\n",
        "        self.dec_blocks = nn.ModuleList()\n",
        "        self.upconvs = nn.ModuleList()\n",
        "        for feat in reversed(features):\n",
        "            # use bottleneck_channels (1024) for the first upconv, then halve each time\n",
        "            self.upconvs.append(nn.ConvTranspose2d(bottleneck_channels, feat, kernel_size=2, stride=2))\n",
        "            self.dec_blocks.append(DoubleConv(feat * 2, feat))\n",
        "            bottleneck_channels = feat  # update for next iteration\n",
        "\n",
        "        self.final_conv = nn.Conv2d(features[0], out_classes, kernel_size=1)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        enc_features = []\n",
        "        for enc_block in self.enc_blocks:\n",
        "            x = enc_block(x)\n",
        "            enc_features.append(x)\n",
        "            x = self.pool(x)\n",
        "        x = self.bottleneck(x)\n",
        "        for i, dec_block in enumerate(self.dec_blocks):\n",
        "            skip_feat = enc_features[-(i+1)]\n",
        "            x = self.upconvs[i](x)\n",
        "            if x.shape[2:] != skip_feat.shape[2:]:\n",
        "                diffY = skip_feat.size(2) - x.size(2)\n",
        "                diffX = skip_feat.size(3) - x.size(3)\n",
        "                x = F.pad(x, [diffX // 2, diffX - diffX//2, diffY // 2, diffY - diffY//2])\n",
        "            x = torch.cat([skip_feat, x], dim=1)\n",
        "            x = dec_block(x)\n",
        "        logits = self.final_conv(x)\n",
        "        return logits\n",
        "\n",
        "\n",
        "# ==============================\n",
        "# COMBINED MODEL\n",
        "# ==============================\n",
        "class DawnUNet(nn.Module):\n",
        "    def __init__(self, in_channels: int = 3, out_classes: int = 1, use_dawn: bool = True):\n",
        "        super(DawnUNet, self).__init__()\n",
        "        self.use_dawn = use_dawn\n",
        "        if use_dawn:\n",
        "            self.dawn = DAWN(in_channels)\n",
        "            self.unet = UNet(in_channels=self.dawn.out_channels, out_classes=out_classes)\n",
        "        else:\n",
        "            self.dawn = None\n",
        "            self.unet = UNet(in_channels=in_channels, out_classes=out_classes)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        if self.use_dawn:\n",
        "            x = self.dawn(x)\n",
        "        logits = self.unet(x)\n",
        "        return logits\n",
        "\n",
        "\n",
        "# ==============================\n",
        "# DATASET\n",
        "# ==============================\n",
        "class SegmentationDataset(Dataset):\n",
        "    def __init__(self, images_dir: str, masks_dir: str, transform_image=None, transform_mask=None):\n",
        "        self.image_files = sorted(os.listdir(images_dir))\n",
        "        self.mask_files = sorted(os.listdir(masks_dir))\n",
        "        assert len(self.image_files) == len(self.mask_files)\n",
        "        self.images_dir = images_dir\n",
        "        self.masks_dir = masks_dir\n",
        "        self.transform_image = transform_image\n",
        "        self.transform_mask = transform_mask\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.images_dir, self.image_files[idx])\n",
        "        mask_path = os.path.join(self.masks_dir, self.mask_files[idx])\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        mask = Image.open(mask_path).convert(\"L\")\n",
        "        if self.transform_image:\n",
        "            image = self.transform_image(image)\n",
        "        if self.transform_mask:\n",
        "            mask = self.transform_mask(mask)\n",
        "        mask = (mask > 0.5).float()\n",
        "        return image, mask\n",
        "\n",
        "\n",
        "# ==============================\n",
        "# TRAINING AND VISUALIZATION\n",
        "# ==============================\n",
        "def main():\n",
        "    # Drive dataset paths\n",
        "    train_images = \"/content/drive/MyDrive/research/unet-ipc-data/DIS-TR/im-good\"\n",
        "    train_masks = \"/content/drive/MyDrive/research/unet-ipc-data/DIS-TR/gt-good\"\n",
        "\n",
        "    transform_img = transforms.Compose([transforms.Resize((256, 256)), transforms.ToTensor()])\n",
        "    transform_mask = transforms.Compose([transforms.Resize((256, 256)), transforms.ToTensor()])\n",
        "\n",
        "    train_dataset = SegmentationDataset(train_images, train_masks, transform_img, transform_mask)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = DawnUNet(in_channels=3, out_classes=1, use_dawn=True).to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "    loss_fn = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    model.train()\n",
        "    for epoch in range(20):\n",
        "        total_loss, total_dice, total_iou = 0.0, 0.0, 0.0\n",
        "\n",
        "        for batch_idx, (images, masks) in enumerate(train_loader):\n",
        "            print(f\"  → Training batch {batch_idx+1}/{len(train_loader)}\")\n",
        "            images, masks = images.to(device), masks.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            logits = model(images)\n",
        "            loss = loss_fn(logits, masks)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item() * images.size(0)\n",
        "\n",
        "            # --- Dice & IoU for this batch ---\n",
        "            with torch.no_grad():\n",
        "                probs = torch.sigmoid(logits)\n",
        "                preds = (probs > 0.5).float()\n",
        "                intersection = (preds * masks).sum(dim=(1,2,3))\n",
        "                union = preds.sum(dim=(1,2,3)) + masks.sum(dim=(1,2,3))\n",
        "                dice = ((2 * intersection + 1e-7) / (union + 1e-7)).mean().item()\n",
        "                iou = ((intersection + 1e-7) / (union - intersection + 1e-7)).mean().item()\n",
        "\n",
        "            total_dice += dice * images.size(0)\n",
        "            total_iou += iou * images.size(0)\n",
        "\n",
        "        avg_loss = total_loss / len(train_loader.dataset)\n",
        "        avg_dice = total_dice / len(train_loader.dataset)\n",
        "        avg_iou = total_iou / len(train_loader.dataset)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/20 - Loss: {avg_loss:.4f}, Dice: {avg_dice:.3f}, IoU: {avg_iou:.3f}\")\n",
        "\n",
        "    # Visualization\n",
        "    os.makedirs(\"output_viz\", exist_ok=True)\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for idx, (img, mask) in enumerate(train_loader):\n",
        "            img, mask = img.to(device), mask.to(device)\n",
        "            pred = torch.sigmoid(model(img))\n",
        "            pred = (pred > 0.5).float()\n",
        "            img_np = img[0].cpu().permute(1, 2, 0).numpy()\n",
        "            pred_np = pred[0, 0].cpu().numpy()\n",
        "            mask_np = mask[0, 0].cpu().numpy()\n",
        "            fig, axs = plt.subplots(1, 3, figsize=(12, 4))\n",
        "            axs[0].imshow(img_np)\n",
        "            axs[0].set_title(\"Input Image\")\n",
        "            axs[1].imshow(pred_np, cmap=\"gray\")\n",
        "            axs[1].set_title(\"Predicted Mask\")\n",
        "            axs[2].imshow(mask_np, cmap=\"gray\")\n",
        "            axs[2].set_title(\"Ground Truth\")\n",
        "            for ax in axs:\n",
        "                ax.axis(\"off\")\n",
        "            plt.tight_layout()\n",
        "            plt.savefig(f\"output_viz/sample_{idx}.png\")\n",
        "            plt.show()\n",
        "            plt.close()\n",
        "            if idx >= 2:\n",
        "                break\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5fVt6Y7ycOa",
        "outputId": "af4e20e2-bdb9-4653-d0d7-6f9375843df5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Oct 19 23:59:01 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   75C    P0             35W /   70W |    2450MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "GPU available: True\n",
            "Device name: Tesla T4\n"
          ]
        }
      ]
    }
  ]
}